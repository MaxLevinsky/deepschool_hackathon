{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67c58b06-84aa-4cb1-8f54-09ec9169f177",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!g2.1\n",
    "import math\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from ultralytics import YOLO, __version__\n",
    "from ultralytics.nn.modules import Detect\n",
    "from ultralytics.nn.tasks import attempt_load_one_weight\n",
    "from ultralytics.engine.trainer import BaseTrainer\n",
    "from ultralytics.utils import yaml_load, LOGGER, RANK\n",
    "from ultralytics.utils.checks import check_yaml\n",
    "from ultralytics.utils.torch_utils import initialize_weights, de_parallel\n",
    "import torch_pruning as tp\n",
    "from prune_trainer import DetectionTrainer_pr\n",
    "from loguru import logger\n",
    "from yolov8_pruning import (save_pruning_performance_graph,  replace_c2f_with_c2f_v2, save_model_v2, final_eval_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347cc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import warnings\n",
    "from ultralytics.utils.checks import check_imgsz\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfc28805-9ebf-417a-8c0c-3c42b1f47e91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T09:26:35.736346Z",
     "iopub.status.busy": "2024-09-02T09:26:35.735980Z",
     "iopub.status.idle": "2024-09-02T09:26:35.776357Z",
     "shell.execute_reply": "2024-09-02T09:26:35.775549Z",
     "shell.execute_reply.started": "2024-09-02T09:26:35.736319Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_v2(self: YOLO, pruning=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Disabled loading new model when pruning flag is set. originated from ultralytics/yolo/engine/model.py\n",
    "    \"\"\"\n",
    "\n",
    "    self._check_is_pytorch_model()\n",
    "    if self.session:  # Ultralytics HUB session\n",
    "        if any(kwargs):\n",
    "            LOGGER.warning('WARNING âš ï¸ using HUB training arguments, ignoring local training arguments.')\n",
    "        kwargs = self.session.train_args\n",
    "    overrides = self.overrides.copy()\n",
    "    overrides.update(kwargs)\n",
    "    if kwargs.get('cfg'):\n",
    "        LOGGER.info(f\"cfg file passed. Overriding default params with {kwargs['cfg']}.\")\n",
    "        overrides = yaml_load(check_yaml(kwargs['cfg']))\n",
    "    overrides['mode'] = 'train'\n",
    "    if not overrides.get('data'):\n",
    "        raise AttributeError(\"Dataset required but missing, i.e. pass 'data=coco128.yaml'\")\n",
    "    if overrides.get('resume'):\n",
    "        overrides['resume'] = self.ckpt_path\n",
    "\n",
    "    self.task = overrides.get('task') or self.task\n",
    "    overrides['verbose'] = False\n",
    "    #self.trainer = TASK_MAP[self.task][1](overrides=overrides, _callbacks=self.callbacks)\n",
    "    self.trainer = DetectionTrainer_pr(overrides=overrides, _callbacks=self.callbacks)\n",
    "\n",
    "\n",
    "    if not pruning:\n",
    "        if not overrides.get('resume'):  # manually set model only if not resuming\n",
    "            self.trainer.model = self.trainer.get_model(weights=self.model if self.ckpt else None, cfg=self.model.yaml)\n",
    "            self.model = self.trainer.model\n",
    "\n",
    "    else:\n",
    "        # pruning mode\n",
    "        self.trainer.pruning = True\n",
    "        self.trainer.model = self.model\n",
    "\n",
    "        # replace some functions to disable half precision saving\n",
    "        self.trainer.save_model = save_model_v2.__get__(self.trainer)\n",
    "        self.trainer.final_eval = final_eval_v2.__get__(self.trainer)\n",
    "\n",
    "    self.trainer.hub_session = self.session  # attach optional HUB session\n",
    "    #return self.trainer\n",
    "    self.trainer.train()\n",
    "    # Update model and cfg after training\n",
    "    if RANK in (-1, 0):\n",
    "        self.model, _ = attempt_load_one_weight(str(self.trainer.best))\n",
    "        self.overrides = self.model.args\n",
    "        self.metrics = getattr(self.trainer.validator, 'metrics', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5881b39c-91f7-462c-b1c0-d35a8429d31b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T09:26:35.777358Z",
     "iopub.status.busy": "2024-09-02T09:26:35.777062Z",
     "iopub.status.idle": "2024-09-02T09:26:35.869531Z",
     "shell.execute_reply": "2024-09-02T09:26:35.869044Z",
     "shell.execute_reply.started": "2024-09-02T09:26:35.777337Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def compare_models_mmacs(model, model_speed, input_example, warmup_steps : int = 10):\n",
    "    [(model(input_example), model_speed(input_example)) for _ in range(warmup_steps)]\n",
    "    \n",
    "    ops_base, params_base = tp.utils.count_ops_and_params(model, input_example)\n",
    "    logger.info(f\"Baseline model complexity: {ops_base/1e6} MMAC, {params_base/1e6} M params\")\n",
    "\n",
    "    ops_speedup, params_speedup = tp.utils.count_ops_and_params(model_speed, input_example)\n",
    "    logger.info(f\"Pruned model complexity: {ops_speedup/1e6} MMAC, {params_speedup/1e6} M params\")\n",
    "\n",
    "    current_speed_up = float(ops_base) / float(ops_speedup)\n",
    "    logger.info(f\"speed up={current_speed_up}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ced9058-15ff-479d-9fa7-99e7906f3189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-29T08:05:42.085272Z",
     "iopub.status.busy": "2024-08-29T08:05:42.084599Z",
     "iopub.status.idle": "2024-08-29T08:05:42.109266Z",
     "shell.execute_reply": "2024-08-29T08:05:42.108604Z",
     "shell.execute_reply.started": "2024-08-29T08:05:42.085243Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prune(\n",
    "    data_yml,\n",
    "    max_map_drop=0.02,\n",
    "    epochs=25,\n",
    "    model_path=\"\",\n",
    "    save_dir=\"./\",\n",
    "    cfg_yml=\"./new_cfg.yaml\",\n",
    "    target_prune_rate=0.5,\n",
    "    iterative_steps=16,\n",
    "    project='./'\n",
    "):\n",
    "    # load trained yolov8 model\n",
    "    model = YOLO(model_path)\n",
    "    model.__setattr__(\"train_v2\", train_v2.__get__(model))\n",
    "    pruning_cfg = yaml_load(check_yaml(cfg_yml))\n",
    "    batch_size = pruning_cfg[\"batch\"]\n",
    "\n",
    "    # use coco128 dataset for 10 epochs fine-tuning each pruning iteration step\n",
    "    # this part is only for sample code, number of epochs should be included in config file\n",
    "    pruning_cfg[\"data\"] = data_yml\n",
    "    pruning_cfg[\"epochs\"] = epochs\n",
    "    model.model.train()\n",
    "    replace_c2f_with_c2f_v2(model.model)\n",
    "    initialize_weights(model.model)  # set BN.eps, momentum, ReLU.inplace\n",
    "    for name, param in model.model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "    pruning_cfg[\"imgsz\"] = check_imgsz(pruning_cfg[\"imgsz\"]) \n",
    "    example_inputs = torch.randn(1, 3, pruning_cfg[\"imgsz\"], pruning_cfg[\"imgsz\"]).to(\n",
    "        model.device\n",
    "    )\n",
    "    macs_list, nparams_list, map_list, pruned_map_list = [], [], [], []\n",
    "    base_macs, base_nparams = tp.utils.count_ops_and_params(model.model, example_inputs)\n",
    "\n",
    "    # do validation before pruning model\n",
    "    pruning_cfg[\"project\"] = project\n",
    "    pruning_cfg[\"name\"] = f\"{save_dir}baseline_val\"\n",
    "    pruning_cfg[\"batch\"] = 1\n",
    "    validation_model = deepcopy(model)\n",
    "    \n",
    "    LOGGER.info(f\"\\n\\nvalidation strats...\")\n",
    "    metric = validation_model.val(**pruning_cfg)\n",
    "    init_map = metric.box.map50\n",
    "    macs_list.append(base_macs)\n",
    "    nparams_list.append(100)\n",
    "    map_list.append(init_map)\n",
    "    pruned_map_list.append(init_map)\n",
    "    LOGGER.info(\n",
    "        f\"Before Pruning: MACs={base_macs / 1e9: .5f} G, #Params={base_nparams / 1e6: .5f} M, mAP={init_map: .5f}\"\n",
    "    )\n",
    "\n",
    "    # prune same ratio of filter based on initial size\n",
    "    pruning_ratio = 1 - math.pow((1 - target_prune_rate), 1 / iterative_steps)\n",
    "\n",
    "    for i in range(iterative_steps):\n",
    "        LOGGER.info(f\"pruning step = {i} starts...\")\n",
    "        model.model.train()\n",
    "        for name, param in model.model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        ignored_layers = []\n",
    "        unwrapped_parameters = []\n",
    "        for m in model.model.modules():\n",
    "            if isinstance(m, (Detect,)):\n",
    "                ignored_layers.append(m)\n",
    "\n",
    "        example_inputs = example_inputs.to(model.device)\n",
    "        pruner = tp.pruner.GroupNormPruner(\n",
    "            model.model,\n",
    "            example_inputs,\n",
    "            importance=tp.importance.GroupNormImportance(),  # L2 norm pruning,\n",
    "            iterative_steps=1,\n",
    "            round_to =8,\n",
    "            pruning_ratio=pruning_ratio,\n",
    "            ignored_layers=ignored_layers,\n",
    "            unwrapped_parameters=unwrapped_parameters,\n",
    "        )\n",
    "\n",
    "        # Test regularization\n",
    "        # output = model.model(example_inputs)\n",
    "        # (output[0].sum() + sum([o.sum() for o in output[1]])).backward()\n",
    "        # pruner.regularize(model.model)\n",
    "\n",
    "        pruner.step()\n",
    "        # pre fine-tuning validation\n",
    "        LOGGER.info(f\"pre fine-tuning validation starts...\")\n",
    "        pruning_cfg[\"name\"] = f\"{save_dir}step_{i}_pre_val\"\n",
    "        pruning_cfg[\"batch\"] = 1\n",
    "        validation_model.model = deepcopy(model.model)\n",
    "        metric = validation_model.val(**pruning_cfg)\n",
    "        pruned_map = metric.box.map50\n",
    "        pruned_macs, pruned_nparams = tp.utils.count_ops_and_params(\n",
    "            pruner.model, example_inputs.to(model.device)\n",
    "        )\n",
    "        current_speed_up = float(macs_list[0]) / pruned_macs\n",
    "        LOGGER.info(\n",
    "            f\"After pruning iter {i + 1}: MACs={pruned_macs / 1e9} G, #Params={pruned_nparams / 1e6} M, \"\n",
    "            f\"mAP={pruned_map}, speed up={current_speed_up}\"\n",
    "        )\n",
    "\n",
    "        # fine-tuning\n",
    "        for name, param in model.model.named_parameters():\n",
    "            param.requires_grad = True\n",
    "        pruning_cfg[\"name\"] = f\"{save_dir}step_{i}_finetune\"\n",
    "        pruning_cfg[\"batch\"] = batch_size  # restore batch size\n",
    "\n",
    "        # return model, pruning_cfg\n",
    "\n",
    "        model.train_v2(pruning=True, **pruning_cfg)\n",
    "\n",
    "        # post fine-tuning validation\n",
    "        pruning_cfg[\"name\"] = f\"{save_dir}step_{i}_post_val\"\n",
    "        pruning_cfg[\"batch\"] = 1\n",
    "        validation_model = YOLO(model.trainer.best)\n",
    "        metric = validation_model.val(**pruning_cfg)\n",
    "        current_map = metric.box.map50\n",
    "        LOGGER.info(f\"After fine tuning mAP={current_map}\")\n",
    "\n",
    "        macs_list.append(pruned_macs)\n",
    "        nparams_list.append(pruned_nparams / base_nparams * 100)\n",
    "        pruned_map_list.append(pruned_map)\n",
    "        map_list.append(current_map)\n",
    "\n",
    "        # remove pruner after single iteration\n",
    "        del pruner\n",
    "\n",
    "        save_pruning_performance_graph(\n",
    "            nparams_list, map_list, macs_list, pruned_map_list\n",
    "        )\n",
    "        LOGGER.info(f\"init_map={init_map}, current_map={current_map}, max_map_drop={max_map_drop}, delta={init_map - current_map }\")\n",
    "        if init_map - current_map > max_map_drop:\n",
    "            LOGGER.info(\"Pruning early stop\")\n",
    "            break\n",
    "\n",
    "    model.export(format=\"onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e738d82d-4a01-4213-a91b-154a28ff966d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "validation strats...\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 11129454 parameters, 16366 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:27<00:00, 19.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.505      0.393        0.4      0.239\n",
      "            pedestrian        548       8844      0.542      0.396      0.428      0.196\n",
      "                people        548       5125      0.569      0.276      0.329      0.124\n",
      "               bicycle        548       1287      0.282       0.15      0.137     0.0591\n",
      "                   car        548      14064      0.716      0.773      0.792      0.564\n",
      "                   van        548       1975      0.501      0.461      0.451      0.317\n",
      "                 truck        548        750      0.517      0.373      0.381      0.256\n",
      "              tricycle        548       1045      0.375      0.326      0.283      0.159\n",
      "       awning-tricycle        548        532      0.304      0.192      0.171      0.103\n",
      "                   bus        548        251      0.709      0.533      0.582      0.414\n",
      "                 motor        548       4886      0.533      0.446      0.445      0.196\n",
      "Speed: 1.5ms preprocess, 15.2ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\baseline_val\u001b[0m\n",
      "Before Pruning: MACs= 14.28176 G, #Params= 11.13947 M, mAP= 0.39999\n",
      "pruning step = 0 starts...\n",
      "pre fine-tuning validation starts...\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 9893086 parameters, 16366 gradients, 24.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:19<00:00, 28.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759     0.0214   0.000178     0.0109    0.00394\n",
      "            pedestrian        548       8844          0          0          0          0\n",
      "                people        548       5125          0          0          0          0\n",
      "               bicycle        548       1287          0          0          0          0\n",
      "                   car        548      14064      0.214    0.00178      0.109     0.0394\n",
      "                   van        548       1975          0          0          0          0\n",
      "                 truck        548        750          0          0          0          0\n",
      "              tricycle        548       1045          0          0          0          0\n",
      "       awning-tricycle        548        532          0          0          0          0\n",
      "                   bus        548        251          0          0          0          0\n",
      "                 motor        548       4886          0          0          0          0\n",
      "Speed: 1.4ms preprocess, 12.9ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_0_pre_val\u001b[0m\n",
      "After pruning iter 1: MACs=12.3326088 G, #Params=9.90247 M, mAP=0.010929091304260475, speed up=1.1580486360679827\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 65 weight(decay=0.0), 72 weight(decay=0.00046875), 71 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\labels.cache... 6471 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6471/6471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\0000137_02220_d_0000163.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\0000140_00118_d_0000002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\9999945_00000_d_0000114.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\9999987_00000_d_0000049.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_0_finetune\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_0_finetune\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/25      5.78G      1.375     0.9618     0.9157         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [02:00<00:00,  5.39it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:08<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.453       0.34       0.34      0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/25      6.04G      1.276     0.8519     0.8939         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:51<00:00,  5.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.451      0.344      0.344      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/25      6.43G      1.298     0.8701     0.8983         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:51<00:00,  5.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.445      0.332      0.338      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/25      5.27G      1.314     0.9061     0.9045        125        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.44      0.339      0.337      0.199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/25      5.24G      1.311     0.9025     0.9046         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.449      0.345      0.345      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/25      8.35G      1.311      0.903     0.9021         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.475      0.344      0.351      0.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/25      7.73G        1.3     0.8874     0.9012         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:51<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.467       0.34      0.348      0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/25      5.62G       1.29     0.8823     0.8996         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.467      0.366      0.364      0.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/25      7.02G      1.286     0.8732      0.897         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.475      0.345      0.356      0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/25      7.27G      1.285     0.8684     0.8949         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.447      0.354       0.35      0.207\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/25      7.05G      1.272     0.8553     0.8958          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.473      0.344      0.356       0.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/25      6.01G      1.264     0.8487     0.8939         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.88it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.462      0.355      0.359      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/25      5.61G      1.259     0.8383     0.8904         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.469      0.358      0.361      0.212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/25      6.59G      1.245     0.8262     0.8906         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.459      0.372      0.365      0.214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/25       8.3G       1.25     0.8272     0.8892        147        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:51<00:00,  5.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.47      0.363      0.367      0.217\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/25      6.15G      1.234     0.8081     0.8894         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.47      0.367      0.366      0.215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/25      6.01G      1.221     0.7931     0.8872         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.476      0.366      0.368      0.216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/25      6.13G      1.215      0.784     0.8849         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.472      0.366      0.369      0.216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/25      7.59G      1.207     0.7723     0.8834         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.47      0.362      0.364      0.215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/25      6.24G      1.193     0.7583      0.882         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.484      0.367      0.373       0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/25      5.95G      1.187     0.7493     0.8809         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.488      0.365       0.37      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/25      4.97G      1.178     0.7402     0.8787         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.476      0.364      0.369      0.219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/25      5.42G      1.173     0.7351     0.8767          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.494      0.366      0.375      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/25      4.61G      1.166      0.725     0.8761         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.489      0.364      0.372       0.22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/25      4.78G      1.157     0.7129     0.8737         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:17<00:00,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.499      0.368      0.377      0.223\n",
      "\n",
      "25 epochs completed in 0.839 hours.\n",
      "Optimizer stripped from pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_0_finetune\\weights\\last.pt, 39.9MB\n",
      "Optimizer stripped from pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_0_finetune\\weights\\best.pt, 39.9MB\n",
      "\n",
      "Validating pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_0_finetune\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 9893086 parameters, 0 gradients, 24.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:16<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.498      0.368      0.377      0.223\n",
      "Speed: 0.5ms preprocess, 2.8ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_0_finetune\u001b[0m\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 9893086 parameters, 0 gradients, 24.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:28<00:00, 18.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.489      0.373      0.378      0.224\n",
      "            pedestrian        548       8844      0.529      0.381      0.413      0.186\n",
      "                people        548       5125      0.556      0.269      0.316       0.12\n",
      "               bicycle        548       1287      0.281      0.154      0.131     0.0554\n",
      "                   car        548      14064      0.708      0.764      0.782       0.55\n",
      "                   van        548       1975      0.462      0.435      0.422      0.295\n",
      "                 truck        548        750      0.538      0.333      0.351      0.237\n",
      "              tricycle        548       1045      0.405      0.252      0.251      0.137\n",
      "       awning-tricycle        548        532      0.268      0.184      0.146     0.0865\n",
      "                   bus        548        251      0.662      0.514      0.545      0.391\n",
      "                 motor        548       4886      0.484      0.449      0.424      0.185\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_0_post_val\u001b[0m\n",
      "After fine tuning mAP=0.3781523666524224\n",
      "init_map=0.39998867291631657, current_map=0.3781523666524224, max_map_drop=0.05, delta=0.021836306263894156\n",
      "pruning step = 1 starts...\n",
      "pre fine-tuning validation starts...\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 8796142 parameters, 16366 gradients, 21.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:21<00:00, 26.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.131     0.0111     0.0691     0.0327\n",
      "            pedestrian        548       8844          0          0          0          0\n",
      "                people        548       5125          0          0          0          0\n",
      "               bicycle        548       1287          0          0          0          0\n",
      "                   car        548      14064      0.586     0.0683      0.327      0.176\n",
      "                   van        548       1975     0.0393     0.0258     0.0205     0.0105\n",
      "                 truck        548        750    0.00605      0.008    0.00308     0.0018\n",
      "              tricycle        548       1045      0.118    0.00191     0.0589     0.0324\n",
      "       awning-tricycle        548        532      0.125    0.00188      0.063     0.0315\n",
      "                   bus        548        251        0.1    0.00398     0.0507     0.0304\n",
      "                 motor        548       4886      0.333   0.000614      0.168     0.0447\n",
      "Speed: 1.6ms preprocess, 12.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_1_pre_val\u001b[0m\n",
      "After pruning iter 2: MACs=10.6261832 G, #Params=8.804926 M, mAP=0.06908970611212324, speed up=1.3440160527253098\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 65 weight(decay=0.0), 72 weight(decay=0.00046875), 71 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\labels.cache... 6471 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6471/6471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\0000137_02220_d_0000163.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\0000140_00118_d_0000002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\9999945_00000_d_0000114.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\9999987_00000_d_0000049.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_1_finetune\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_1_finetune\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/25      5.59G      1.508      1.089     0.9434         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:50<00:00,  5.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.436      0.313      0.309      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/25      5.87G      1.338     0.9026     0.9046         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:45<00:00,  6.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.442      0.319       0.32      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/25      6.25G      1.343     0.9031     0.9063         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.431      0.316      0.318      0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/25      5.06G      1.351     0.9304     0.9098        125        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.443      0.315      0.321      0.186\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/25      5.05G      1.342     0.9233     0.9093         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.425      0.329      0.325      0.188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/25      8.14G      1.343     0.9236      0.907         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:44<00:00,  6.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.459      0.325      0.326      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/25      7.54G       1.33     0.9083     0.9059         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:44<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.436      0.332      0.333      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/25      5.45G       1.32     0.9023     0.9038         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.454      0.343      0.342      0.199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/25      6.83G      1.317     0.8946      0.902         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.451      0.328      0.337      0.194\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/25      7.08G      1.315     0.8903     0.8998         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.444      0.333      0.333      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/25      6.85G      1.301     0.8761        0.9          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.26it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.444      0.341      0.339      0.197\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/25      5.82G      1.295     0.8693     0.8985         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.27it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.437      0.344      0.336      0.195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/25      5.41G      1.287     0.8584     0.8948         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:44<00:00,  6.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.462      0.333      0.339      0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/25      6.41G      1.274      0.847     0.8946         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.441      0.354      0.348      0.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/25      8.12G       1.28     0.8485     0.8936        147        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:43<00:00,  6.23it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.467      0.353      0.353      0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/25      5.95G      1.259     0.8253     0.8933         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.465      0.339      0.343      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/25      5.82G      1.245     0.8096     0.8914         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.463       0.34      0.343      0.199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/25      5.94G      1.241     0.7997      0.889         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.473      0.333       0.34      0.198\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/25      7.39G      1.231       0.79     0.8869         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.471      0.345      0.349      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/25      6.05G      1.218     0.7763     0.8858         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.465      0.353      0.353      0.205\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/25      5.75G      1.213     0.7688     0.8852         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.58it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.472      0.348      0.352      0.207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/25      4.77G      1.205     0.7603     0.8829         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.55it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.472      0.351      0.354      0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/25      5.24G      1.201     0.7551     0.8813          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.478       0.35      0.356      0.209\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/25      4.42G      1.193     0.7458     0.8806         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.478       0.35      0.353      0.206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/25      4.59G      1.189     0.7366      0.879         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:38<00:00,  6.57it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:16<00:00,  1.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.478      0.356      0.357      0.208\n",
      "\n",
      "25 epochs completed in 0.787 hours.\n",
      "Optimizer stripped from pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_1_finetune\\weights\\last.pt, 35.5MB\n",
      "Optimizer stripped from pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_1_finetune\\weights\\best.pt, 35.5MB\n",
      "\n",
      "Validating pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_1_finetune\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 8796142 parameters, 0 gradients, 21.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:16<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.478      0.351      0.356      0.209\n",
      "Speed: 0.5ms preprocess, 2.5ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_1_finetune\u001b[0m\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 8796142 parameters, 0 gradients, 21.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:27<00:00, 19.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.479      0.346      0.355      0.209\n",
      "            pedestrian        548       8844      0.505      0.349      0.382      0.169\n",
      "                people        548       5125      0.576      0.245      0.314      0.117\n",
      "               bicycle        548       1287      0.263      0.145      0.117     0.0521\n",
      "                   car        548      14064      0.712      0.743      0.768      0.533\n",
      "                   van        548       1975      0.443      0.426      0.386       0.27\n",
      "                 truck        548        750      0.473      0.323      0.321      0.211\n",
      "              tricycle        548       1045       0.39      0.214      0.223      0.124\n",
      "       awning-tricycle        548        532      0.285      0.148      0.126     0.0779\n",
      "                   bus        548        251      0.614       0.49      0.521      0.366\n",
      "                 motor        548       4886      0.525      0.377      0.392      0.169\n",
      "Speed: 1.6ms preprocess, 13.7ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_1_post_val\u001b[0m\n",
      "After fine tuning mAP=0.35492800515640405\n",
      "init_map=0.39998867291631657, current_map=0.35492800515640405, max_map_drop=0.05, delta=0.04506066775991252\n",
      "pruning step = 2 starts...\n",
      "pre fine-tuning validation starts...\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 7773566 parameters, 16366 gradients, 18.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:19<00:00, 28.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed: 1.7ms preprocess, 12.9ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_pre_val\u001b[0m\n",
      "After pruning iter 3: MACs=9.1339784 G, #Params=7.78175 M, mAP=0.0, speed up=1.5635860054146833\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 65 weight(decay=0.0), 72 weight(decay=0.00046875), 71 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\labels.cache... 6471 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6471/6471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\0000137_02220_d_0000163.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\0000140_00118_d_0000002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\9999945_00000_d_0000114.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\9999987_00000_d_0000049.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/25      5.41G      1.847      1.532      1.034         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:48<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.346      0.251      0.237      0.131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/25      5.67G      1.497      1.072     0.9391         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:41<00:00,  6.37it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.375      0.272       0.26      0.146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/25      6.06G       1.47      1.039     0.9331         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.371      0.279      0.269       0.15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/25      4.76G      1.461      1.045     0.9335        125        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:39<00:00,  6.52it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.395      0.283      0.276      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/25      4.85G      1.442      1.029     0.9307         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.396      0.291      0.284       0.16\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/25      7.84G      1.434      1.019     0.9249         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.41      0.289      0.287      0.164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/25      7.35G      1.415     0.9984     0.9232         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.417      0.288      0.294      0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/25      5.25G      1.402     0.9862     0.9205         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:39<00:00,  6.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.407      0.306      0.297      0.168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/25      6.64G      1.396     0.9744     0.9176         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.414      0.309      0.305      0.174\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/25      6.89G      1.393      0.968     0.9152         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.399      0.307      0.299      0.171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/25       6.6G      1.375     0.9506     0.9143          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.409      0.315      0.309      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/25      5.58G      1.368     0.9439     0.9125         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:39<00:00,  6.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.421      0.303      0.303      0.173\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/25      5.22G       1.36     0.9321     0.9089         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.421       0.31      0.311      0.176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/25      6.26G      1.346     0.9176     0.9085         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.416      0.317      0.311      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/25       7.8G      1.351     0.9186     0.9071        147        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.433      0.323       0.32      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/25      5.69G      1.319     0.8872     0.9051         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.431      0.307      0.311      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/25      5.62G      1.306     0.8711      0.903         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.421      0.313      0.315      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/25      5.74G      1.299     0.8615     0.9005         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:35<00:00,  6.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.417      0.329      0.323      0.185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/25      7.34G      1.292     0.8489     0.8987         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:35<00:00,  6.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.441      0.313       0.32      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/25      5.85G      1.278     0.8366     0.8974         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.438      0.319      0.319      0.183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/25      5.43G      1.273     0.8279     0.8969         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.435      0.322      0.321      0.184\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/25      4.57G      1.264     0.8195     0.8944         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.444      0.321      0.323      0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/25      4.97G       1.26     0.8141     0.8929          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.438      0.329      0.327      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/25      4.16G      1.254     0.8058     0.8923         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.443      0.327       0.33      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/25      4.39G      1.247     0.7972     0.8904         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:35<00:00,  6.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:16<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.437      0.334       0.33      0.191\n",
      "\n",
      "25 epochs completed in 0.762 hours.\n",
      "Optimizer stripped from pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\\weights\\last.pt, 31.4MB\n",
      "Optimizer stripped from pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\\weights\\best.pt, 31.4MB\n",
      "\n",
      "Validating pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 7773566 parameters, 0 gradients, 18.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:15<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.437      0.335       0.33      0.191\n",
      "Speed: 0.5ms preprocess, 2.2ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\u001b[0m\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 7773566 parameters, 0 gradients, 18.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:26<00:00, 20.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.459      0.328      0.333      0.192\n",
      "            pedestrian        548       8844      0.482       0.32      0.346      0.148\n",
      "                people        548       5125      0.512      0.232      0.281      0.104\n",
      "               bicycle        548       1287      0.256     0.0979     0.0959     0.0396\n",
      "                   car        548      14064      0.695      0.722      0.749      0.514\n",
      "                   van        548       1975      0.419      0.398       0.37      0.255\n",
      "                 truck        548        750      0.482        0.3      0.303      0.197\n",
      "              tricycle        548       1045      0.392      0.225      0.219      0.115\n",
      "       awning-tricycle        548        532       0.28      0.154      0.126     0.0744\n",
      "                   bus        548        251       0.62      0.446      0.472       0.32\n",
      "                 motor        548       4886      0.455      0.385      0.372      0.157\n",
      "Speed: 1.6ms preprocess, 12.6ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001b[1mpruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_post_val\u001b[0m\n",
      "After fine tuning mAP=0.33329544893518914\n",
      "init_map=0.39998867291631657, current_map=0.33329544893518914, max_map_drop=0.05, delta=0.06669322398112743\n",
      "Pruning early stop\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CPU (13th Gen Intel Core(TM) i7-1360P)\n",
      "Model summary (fused): 185 layers, 7773566 parameters, 0 gradients, 18.2 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 14, 8400) (30.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.15.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 2.0s, saved as 'pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\\weights\\best.onnx' (29.9 MB)\n",
      "\n",
      "Export complete (5.6s)\n",
      "Results saved to \u001b[1mC:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=pruning_hackaton1\\visdrone_yolo8s_640_pruned_27ep\\step_2_finetune\\weights\\best.onnx imgsz=640 data=./data.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')\n",
    "BASELINE_PT = './visdrone_yolo8s_640/visdrone_yolo8s_640/weights/best.pt'\n",
    "prune(data_yml = \"./data.yaml\", \\\n",
    "      max_map_drop = 0.05, \\\n",
    "      epochs =  25, \\\n",
    "      model_path = BASELINE_PT  ,\\\n",
    "      project = './pruning_hackaton1/',\n",
    "      save_dir='./visdrone_yolo8s_640_pruned_27ep/', \\\n",
    "      cfg_yml = './prune_custom.yaml', \\\n",
    "      target_prune_rate = 0.4 ,\\\n",
    "      iterative_steps = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037ad3e-a72c-41db-b7b6-3412a2c890b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a66e276d-67eb-45eb-9b79-ac0bed441219",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Compare MACs and #of Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "073291eb-8a0a-41db-91fb-2bc8956aa4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PRUNED_PT = 'pruning_hackaton1/visdrone_yolo8s_640_pruned_27ep/step_2_finetune/weights/best.pt'\n",
    "BASELINE_PT = 'visdrone_yolo8s_640/visdrone_yolo8s_640/weights/best.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6bc31ca-5111-401d-886f-abf3114f39c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T08:34:00.715870Z",
     "iopub.status.busy": "2024-09-02T08:34:00.715151Z",
     "iopub.status.idle": "2024-09-02T08:34:00.887190Z",
     "shell.execute_reply": "2024-09-02T08:34:00.886570Z",
     "shell.execute_reply.started": "2024-09-02T08:34:00.715846Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_baseline = YOLO(BASELINE_PT).model.to(\"cuda:0\")\n",
    "model_speeduped = YOLO(PRUNED_PT).model.to(\"cuda:0\")\n",
    "example_in = torch.rand(1,3,640,640, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "249a18fd-049e-4ece-87b9-e1b5c001ab75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T08:34:00.990794Z",
     "iopub.status.busy": "2024-09-02T08:34:00.990491Z",
     "iopub.status.idle": "2024-09-02T08:34:01.198963Z",
     "shell.execute_reply": "2024-09-02T08:34:01.198234Z",
     "shell.execute_reply.started": "2024-09-02T08:34:00.990772Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-13 07:59:30.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompare_models_mmacs\u001b[0m:\u001b[36m5\u001b[0m - \u001b[1mBaseline model complexity: 14281.7608 MMAC, 11.13947 M params\u001b[0m\n",
      "\u001b[32m2024-10-13 07:59:30.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompare_models_mmacs\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mPruned model complexity: 9133.9784 MMAC, 7.78175 M params\u001b[0m\n",
      "\u001b[32m2024-10-13 07:59:30.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcompare_models_mmacs\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mspeed up=1.5635860054146833\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "compare_models_mmacs(model = model_baseline, model_speed = model_speeduped,\\\n",
    "                     input_example = example_in )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d322200-7bd5-43bb-870c-8869dfa53f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7da52143-55ea-45bc-b4c7-0d506d53ed11",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd844422-56a7-4d6f-8e17-abe07d686798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T08:44:45.189394Z",
     "iopub.status.busy": "2024-09-02T08:44:45.189021Z",
     "iopub.status.idle": "2024-09-02T08:45:34.257324Z",
     "shell.execute_reply": "2024-09-02T08:45:34.256637Z",
     "shell.execute_reply.started": "2024-09-02T08:44:45.189374Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ updating to 'imgsz=640'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 168 layers, 11129454 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:16<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759        0.5      0.395        0.4      0.239\n",
      "            pedestrian        548       8844      0.522      0.402      0.428      0.197\n",
      "                people        548       5125      0.561      0.279      0.328      0.124\n",
      "               bicycle        548       1287      0.272      0.148      0.131     0.0567\n",
      "                   car        548      14064      0.714      0.776      0.795      0.565\n",
      "                   van        548       1975      0.501      0.463      0.452      0.318\n",
      "                 truck        548        750      0.507      0.379       0.39      0.257\n",
      "              tricycle        548       1045      0.377      0.332      0.286      0.161\n",
      "       awning-tricycle        548        532      0.312       0.19      0.172      0.102\n",
      "                   bus        548        251      0.707      0.538      0.579      0.411\n",
      "                 motor        548       4886      0.526      0.446      0.443      0.197\n",
      "Speed: 0.6ms preprocess, 5.3ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\irady\\STRATIM\\tg_bot_cv\\runs\\detect\\val\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_baseline = YOLO(BASELINE_PT) #.model.to(\"cuda:0\")\n",
    "res = model_baseline.val(data =\"./data.yaml\", imgsz = (640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11bde02d-9c2d-4c45-abea-990b20667031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T08:40:41.762453Z",
     "iopub.status.busy": "2024-09-02T08:40:41.762085Z",
     "iopub.status.idle": "2024-09-02T08:41:30.762404Z",
     "shell.execute_reply": "2024-09-02T08:41:30.761651Z",
     "shell.execute_reply.started": "2024-09-02T08:40:41.762434Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ updating to 'imgsz=640'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 7773566 parameters, 0 gradients, 18.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:15<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.439      0.335       0.33      0.191\n",
      "            pedestrian        548       8844      0.452      0.336      0.345      0.147\n",
      "                people        548       5125      0.499      0.242      0.279      0.104\n",
      "               bicycle        548       1287      0.215      0.109     0.0933     0.0385\n",
      "                   car        548      14064      0.681      0.728       0.75      0.514\n",
      "                   van        548       1975       0.41      0.409      0.367      0.254\n",
      "                 truck        548        750      0.456      0.307        0.3      0.196\n",
      "              tricycle        548       1045      0.378      0.233      0.211      0.113\n",
      "       awning-tricycle        548        532      0.263       0.15      0.122     0.0729\n",
      "                   bus        548        251      0.593      0.441      0.464      0.318\n",
      "                 motor        548       4886      0.441      0.396      0.371      0.155\n",
      "Speed: 0.6ms preprocess, 5.2ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\irady\\STRATIM\\tg_bot_cv\\runs\\detect\\val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_speeduped = YOLO(PRUNED_PT)\n",
    "res = model_speeduped.val(data = \"./data.yaml\", imgsz = (640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363da26d-0ba4-4f7c-8657-4502d0f8c6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f461e89a-066e-4184-bc86-b6e94e1459cd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49a37532-4f2f-46ea-aa14-3fdc5c68aaeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-02T13:50:52.050463Z",
     "iopub.status.busy": "2024-09-02T13:50:52.049956Z",
     "iopub.status.idle": "2024-09-02T13:50:52.084713Z",
     "shell.execute_reply": "2024-09-02T13:50:52.083867Z",
     "shell.execute_reply.started": "2024-09-02T13:50:52.050435Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tune_after_pruning_single(model_path, cfg_yml, data_yml, epochs, resume=False  ):\n",
    "    model = YOLO(model_path)\n",
    "    model.__setattr__(\"train_v2\", train_v2.__get__(model))\n",
    "    pruning_cfg = yaml_load(check_yaml(cfg_yml))\n",
    "    pruning_cfg[\"data\"] = data_yml\n",
    "    pruning_cfg[\"epochs\"] = epochs\n",
    "    pruning_cfg[\"name\"] = f\"tune_afterfinal_pruning\"\n",
    "    pruning_cfg[\"imgsz\"] = check_imgsz(pruning_cfg[\"imgsz\"]) \n",
    "\n",
    "    # pruning_cfg[\"lr0\"] = 0.005\n",
    "    # pruning_cfg[\"lrf\"] = 0.001 \n",
    "    pruning_cfg[\"resume\"]=resume\n",
    "\n",
    "    model.model.train()\n",
    "    replace_c2f_with_c2f_v2(model.model)\n",
    "    initialize_weights(model.model)  # set BN.eps, momentum, ReLU.inplace\n",
    "    model.model.train()\n",
    "    for name, param in model.model.named_parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    model.train_v2(pruning=True, **pruning_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ebefcfd-f2ca-42ec-bf80-80d98133dfce",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 65 weight(decay=0.0), 72 weight(decay=0.00046875), 71 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\labels.cache... 6471 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6471/6471 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\0000137_02220_d_0000163.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\0000140_00118_d_0000002.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\9999945_00000_d_0000114.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-train\\images\\9999987_00000_d_0000049.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to tune_afterfinal_pruning\\labels.jpg... \n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mtune_afterfinal_pruning\u001b[0m\n",
      "Starting training for 30 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/30      5.28G      1.317      0.874     0.9002         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:49<00:00,  5.94it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.439      0.324      0.325      0.187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/30      5.54G      1.309     0.8665     0.8977         93        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:41<00:00,  6.36it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.43      0.317      0.316      0.183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/30      5.94G      1.341     0.8915     0.9039         71        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.41      0.308      0.308      0.175\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/30      4.62G      1.356     0.9243     0.9089        125        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:39<00:00,  6.50it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.417      0.308      0.305      0.174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/30      4.74G      1.359     0.9286     0.9111         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.418      0.317      0.313       0.18\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/30      7.72G      1.365     0.9342     0.9098         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:39<00:00,  6.51it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.412       0.32       0.31      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/30      7.22G      1.355     0.9232     0.9095         61        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.411      0.314      0.307      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/30      5.13G      1.346     0.9203      0.908         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.425      0.322      0.315      0.182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/30      6.52G      1.345     0.9148     0.9066         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.421      0.318      0.315      0.181\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/30      6.77G      1.348     0.9149     0.9053         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.44it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.423      0.314      0.312      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/30      6.47G      1.333     0.9018     0.9054          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.43it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.431      0.317      0.311      0.178\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/30      5.47G       1.33     0.8997     0.9046         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.46it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.428      0.317      0.311      0.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/30       5.1G      1.326     0.8908     0.9013         99        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.42it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.431      0.318      0.315       0.18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/30      6.14G      1.314     0.8802     0.9021         48        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:39<00:00,  6.49it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.437       0.32      0.323      0.185\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/30      7.68G      1.321     0.8845     0.9008        147        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.431      0.327       0.32      0.186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/30      4.34G      1.324     0.8981     0.9039         66        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.48it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.438      0.322      0.318      0.184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/30      7.08G      1.329      0.898     0.9035         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.442      0.326      0.327      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/30      6.57G      1.318     0.8847     0.9022         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.442      0.326      0.327      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/30      3.91G      1.315     0.8771     0.9005         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.45it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.453      0.326      0.329       0.19\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/30      5.92G        1.3     0.8698     0.9002         47        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:40<00:00,  6.47it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.44      0.328      0.326      0.189\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/30      5.84G      1.281     0.8382     0.8973         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:35<00:00,  6.80it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.456      0.324      0.332      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/30      4.48G      1.265     0.8226     0.8953         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.85it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.453      0.313      0.324      0.189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/30      4.97G       1.26     0.8191     0.8941          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.454      0.328       0.33      0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/30      5.55G      1.254     0.8086     0.8917         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.83it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.444      0.327       0.33       0.19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/30      5.31G      1.251     0.8005     0.8911         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:35<00:00,  6.82it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.45      0.331      0.331      0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/30      4.64G      1.241     0.7922     0.8893         64        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.86it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.462      0.326      0.333      0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/30      4.85G      1.236     0.7848     0.8893         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:35<00:00,  6.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.467      0.329      0.336      0.195\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/30      5.56G       1.23      0.776     0.8869         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:35<00:00,  6.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.464      0.325      0.331      0.192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/30      4.76G      1.227     0.7711     0.8863        104        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:34<00:00,  6.84it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:07<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759       0.47      0.329      0.336      0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/30      4.85G      1.216      0.759     0.8838          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 648/648 [01:35<00:00,  6.81it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:16<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.458      0.333      0.337      0.195\n",
      "\n",
      "30 epochs completed in 0.914 hours.\n",
      "Optimizer stripped from tune_afterfinal_pruning\\weights\\last.pt, 31.4MB\n",
      "Optimizer stripped from tune_afterfinal_pruning\\weights\\best.pt, 31.4MB\n",
      "\n",
      "Validating tune_afterfinal_pruning\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 7773566 parameters, 0 gradients, 18.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:15<00:00,  1.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.457      0.333      0.337      0.195\n",
      "Speed: 0.5ms preprocess, 2.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mtune_afterfinal_pruning\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "model_p = 'pruning_hackaton1/visdrone_yolo8s_640_pruned_27ep/step_2_finetune/weights/best.pt'\n",
    "cfg_yml = './prune_custom.yaml'\n",
    "data_yml = \"./data.yaml\"\n",
    "epochs = 30\n",
    "tune_after_pruning_single(model_path = model_p, cfg_yml = cfg_yml, data_yml=data_yml, epochs = epochs  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1e10dec-9788-408a-8df9-d18fd1cef29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING âš ï¸ updating to 'imgsz=640'. 'train' and 'val' imgsz must be an integer, while 'predict' and 'export' imgsz may be a [h, w] list or an integer, i.e. 'yolo export imgsz=640,480' or 'yolo export imgsz=640'\n",
      "Ultralytics YOLOv8.0.216 ðŸš€ Python-3.10.11 torch-2.1.2+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "Model summary (fused): 185 layers, 7773566 parameters, 0 gradients, 18.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\irady\\GitHub\\not_GitProjects\\DeepSchool\\HACK_part_1\\VisDrone2019-DET-val\\labels.cache... 548 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 548/548 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:16<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        548      38759      0.458      0.334      0.337      0.196\n",
      "            pedestrian        548       8844      0.468      0.346      0.358      0.155\n",
      "                people        548       5125       0.52      0.241      0.287      0.106\n",
      "               bicycle        548       1287      0.224      0.126     0.0999     0.0399\n",
      "                   car        548      14064      0.672      0.739      0.757      0.521\n",
      "                   van        548       1975      0.429      0.396      0.362       0.25\n",
      "                 truck        548        750        0.5      0.301      0.322      0.209\n",
      "              tricycle        548       1045      0.395      0.229      0.217      0.113\n",
      "       awning-tricycle        548        532      0.268      0.143      0.121     0.0716\n",
      "                   bus        548        251      0.602      0.438      0.467       0.33\n",
      "                 motor        548       4886      0.503      0.377      0.381      0.162\n",
      "Speed: 0.7ms preprocess, 3.9ms inference, 0.0ms loss, 4.9ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\irady\\STRATIM\\tg_bot_cv\\runs\\detect\\val3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model_speeduped = YOLO('tune_afterfinal_pruning/weights/best.pt')\n",
    "res = model_speeduped.val(data = \"./data.yaml\", imgsz = (640, 640))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "notebookId": "e4887e4f-dc55-4833-97f9-a4f4bd37eae4",
  "notebookPath": "prune1.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
